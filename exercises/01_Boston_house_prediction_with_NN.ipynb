{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Exercise 1: Supervised learning / Regression\n",
    "\n",
    "## Learning outcomes:\n",
    " - Machine learning methods for regression\n",
    "     - Linear regression\n",
    "     - Non-linear regression\n",
    "     - Multivariate regression\n",
    "     - Neural networks\n",
    " - Model selection\n",
    " - Error / cost\n",
    " - Feature selection\n",
    " - (Data)\n",
    " - Machine learning open source tools:\n",
    "     - Keras, SciKit-Learn, Jupyter Notebooks, Matplotlib\n",
    "\n",
    "## Structure\n",
    "1. Linear regression\n",
    "    1. Manually fit a model to data\n",
    "    2. Use iterative algorithm to learn a model\n",
    "2. Non-linear regression\n",
    "    1. Underfitting a model\n",
    "    2. Overfitting a model\n",
    "    3. Model selection\n",
    "3. Multivariate regression\n",
    "    1. \n",
    "4. Neural networks\n",
    "\n",
    "## Dataset: Boston house price predicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Open Source Machine Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = [12.0, 8.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Keras, one of the most popular Open Source Deep Learning library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Keras is an easy to use Deep Learning library for Python\n",
    "import keras\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# Load Sequential model architecture\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Load Dense and Dropout layers ?\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Load RMSprop optimizer to minimize cost to train the network\n",
    "from keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_error(x_test, y_test, y_test_pred):\n",
    "    pylab.plot([x_test, x_test], [y_test, y_test_pred], 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "\n",
    "# Choose AVG number of rooms as feature\n",
    "X = boston.data[:, boston.feature_names.tolist().index('RM')]\n",
    "\n",
    "# Target / desired output\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Visualising data\n",
    "It is a good idea to visualise the data before running any machine learning algorithms to see if the data makes any sense and if it is possible to learn from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pylab.plot(X, y, '.')\n",
    "pylab.grid()\n",
    "pylab.xlabel('Average number of rooms')\n",
    "pylab.ylabel('Average price of the house')\n",
    "pylab.savefig('house_num_rooms_vs_price.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1: Manually fitting a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our simple linear model\n",
    "def predict(x, w, b):\n",
    "    return w*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init weight and bias\n",
    "w = 1\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(x_train, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure()\n",
    "xs = np.linspace(X.min(), X.max(), 100)\n",
    "pylab.plot(xs, predict(xs, w, b))\n",
    "pylab.plot(x_train, y_train, 'b+')\n",
    "#pylab.plot(x_test, y_test, '.')\n",
    "pylab.xlabel('Average number of rooms')\n",
    "pylab.ylabel('Average price of the house')\n",
    "plot_prediction_error(x_train, y_train, predict(x_train, w, b))\n",
    "pylab.legend(['Model', 'Train', 'Test', 'Error'])\n",
    "pylab.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising error function\n",
    "Error function shows how the weight *w* affects the error. Notice that we did not study bias term *b* in the sake of simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict house prices with weights from 1 to 20 and bias = -10, 0, 10\n",
    "ws = np.linspace(-10,40,100)\n",
    "for b in [0]: #[-20, -10, 0, 10, 30]:\n",
    "    errs = []\n",
    "    for w in ws:\n",
    "        errs.append(mean_squared_error(y_train, predict(x_train, w, b)))\n",
    "    # Visualise error function\n",
    "    pylab.plot(ws, errs)\n",
    "#pylab.legend(['bias = -20', 'bias = -10', 'bias = 0', 'bias = 10', 'bias = 20'])\n",
    "pylab.legend(['bias = 0'])\n",
    "pylab.grid()\n",
    "pylab.xlabel('Weight w')\n",
    "pylab.ylabel('Cost: Mean squared error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Linear regression (from SciKit-Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(x_train.reshape(-1,1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = clf.coef_\n",
    "b = clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_error = mean_squared_error(y_train, clf.predict(x_train.reshape(-1,1)))\n",
    "test_error = mean_squared_error(y_test, clf.predict(x_test.reshape(-1,1)))\n",
    "print('Train error=%f test error=%f' % (train_error, test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pylab.figure()\n",
    "\n",
    "# Generate data to visualise model\n",
    "xs = np.linspace(X.min(), X.max(), 100)\n",
    "\n",
    "# Plot stuff\n",
    "pylab.plot(xs, clf.predict(xs.reshape(-1, 1)))\n",
    "pylab.plot(x_test, y_test, 'g.')\n",
    "pylab.plot(x_train, y_train, 'b+')\n",
    "plot_prediction_error(x_train, y_train, clf.predict(x_train.reshape(-1,1)))\n",
    "\n",
    "# Configure figure axes etc\n",
    "pylab.xlabel('Average number of rooms')\n",
    "pylab.ylabel('Average price of the house')\n",
    "pylab.legend(['Model', 'Test', 'Train', 'Error'])\n",
    "pylab.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Linear regression with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "\n",
    "# Choose AVG number of rooms as feature\n",
    "X = boston.data[:, boston.feature_names.tolist().index('RM')]\n",
    "\n",
    "# Target / desired output\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a model (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It is a good idea to clear the session (remove graphs etc from GPU/CPU) before defining a new model\n",
    "K.clear_session()\n",
    "\n",
    "# Init new feedforward network model from keras\n",
    "model = Sequential()\n",
    "\n",
    "# In linear regression we don't have hidden layers. Just the output which is connected to input.\n",
    "model.add(Dense(1, activation='linear', input_shape=(1,)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss/cost function and optimizer and compile network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=RMSprop(lr=.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_error = mean_squared_error(y_train, model.predict(x_train, verbose=0))\n",
    "test_error = mean_squared_error(y_test, model.predict(x_test, verbose=0))\n",
    "print('Train error=%f test error=%f' % (train_error, test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pylab.figure()\n",
    "xs = np.linspace(3, 10, 20)\n",
    "pylab.plot(xs, model.predict(xs.reshape(-1, 1)))\n",
    "pylab.plot(x_test, y_test, '.')\n",
    "pylab.plot(x_train, y_train, '+')\n",
    "pylab.legend(['Model', 'Test', 'Train'])\n",
    "pylab.xlabel('Average number of rooms')\n",
    "pylab.ylabel('Average price of the house')\n",
    "pylab.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.2 Non-linear regression\n",
    "Here we use non-linear functions to predict house prices instead of a linear function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "boston = load_boston()\n",
    "\n",
    "# Choose AVG number of rooms as feature\n",
    "X = boston.data[:, boston.feature_names.tolist().index('RM')]\n",
    "\n",
    "# Target / desired output\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting linear and two non-linear functions\n",
    "xs = np.linspace(-1,1,100)\n",
    "bias = 0\n",
    "y1 = xs + bias\n",
    "y2 = np.power(xs, 2) + xs + bias\n",
    "y3 = np.power(xs, 3) + np.power(xs, 2) + xs + bias\n",
    "\n",
    "pylab.plot(xs, y1)\n",
    "pylab.plot(xs, y2)\n",
    "pylab.plot(xs, y3)\n",
    "pylab.grid()\n",
    "pylab.legend(['Linear: $X + b$', 'Non-linear: $X^2+X+b$', 'Non-linear: $X^3+X^2+X+b$'])\n",
    "pylab.savefig('non-linear-functions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that generates polynomial features\n",
    "def gen_features(x, n=3):\n",
    "    x_out = []\n",
    "    for i in range(1, n+1):\n",
    "        x_out.append(x.reshape(-1, 1)**i)\n",
    "    \n",
    "    return np.hstack(x_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models with higher degree polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pylab.plot(x_test, y_test, 'o')\n",
    "pylab.plot(x_train, y_train, '.')\n",
    "\n",
    "for p in range(1, 4):\n",
    "    # Gen data\n",
    "    x_train_tmp = gen_features(x_train, p)\n",
    "    x_test_tmp = gen_features(x_test, p)\n",
    "    \n",
    "    # Train a model\n",
    "    clf.fit(x_train_tmp, y_train)\n",
    "    \n",
    "    # Plot\n",
    "    xs = np.linspace(3,9,100).reshape(-1,1)\n",
    "    xs = gen_features(xs, p)\n",
    "    pred = clf.predict(xs)\n",
    "    pylab.plot(np.linspace(3, 9, 100), pred)\n",
    "\n",
    "pylab.legend(['Test', 'Train', 'Model 1', 'Model 2', 'Model 3'])\n",
    "pylab.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Train a model using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets generate some features\n",
    "\n",
    "x_train2 = gen_features(x_train, 2)\n",
    "x_test2 = gen_features(x_test, 2)\n",
    "\n",
    "x_train3 = gen_features(x_train, 3)\n",
    "x_test3 = gen_features(x_test, 3)\n",
    "\n",
    "x_train5 = gen_features(x_train, 5)\n",
    "x_test5 = gen_features(x_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is a good idea to clear the session (remove graphs etc from GPU/CPU) before defining a new model\n",
    "K.clear_session()\n",
    "\n",
    "# Init new feedforward network model from keras\n",
    "model = Sequential()\n",
    "\n",
    "# In linear regression we don't have hidden layers. Just the output which is connected to input.\n",
    "model.add(Dense(1, activation='linear', input_shape=(x_train2.shape[1],)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=RMSprop(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train2, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = mean_squared_error(y_train, model.predict(x_train2, verbose=0))\n",
    "test_error = mean_squared_error(y_test, model.predict(x_test2, verbose=0))\n",
    "print('Train error=%f test error=%f' % (train_error, test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test2, verbose=0)\n",
    "pylab.plot(y_test, y_test_pred, '.')\n",
    "pylab.plot([0,50],[0,50],'k-')\n",
    "pylab.xlabel('Ground truth')\n",
    "pylab.ylabel('Prediction')\n",
    "pylab.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.3 Multivariate regression\n",
    "\n",
    "#### Tasks:\n",
    "* Choose features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "\n",
    "# Choose AVG number of rooms as feature\n",
    "X = boston.data\n",
    "\n",
    "# Target / desired output\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, X.shape[1]):\n",
    "    pylab.subplot(4, 4, i+1)\n",
    "    pylab.plot(y, X[:, i], '.')\n",
    "    pylab.title(str(i) + ': ' + boston.feature_names.tolist()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtmp = X[:, [0, 5]]\n",
    "# TODO: You can try these\n",
    "# Xtmp = X[:, [0, 1, 2]]\n",
    "# Xtmp = X[:, [0, 6, 4]]\n",
    "# Xtmp = X[:, [0, 5, 12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(Xtmp, y, test_size=0.2, random_state=42)\n",
    "# Train\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = mean_squared_error(y_train, clf.predict(x_train))\n",
    "test_error = mean_squared_error(y_test, clf.predict(x_test))\n",
    "print('Train error=%f test error=%f' % (train_error, test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure()\n",
    "pylab.plot(y_test, clf.predict(x_test), '.')\n",
    "pylab.plot(y_train, clf.predict(x_train), '+')\n",
    "pylab.plot([np.min(y_test), np.max(y_test)], [np.min(y_test), np.max(y_test)], 'k-')\n",
    "pylab.legend(['Test', 'Train', 'Perfect model'])\n",
    "pylab.xlabel('Ground truth')\n",
    "pylab.ylabel('Predicted')\n",
    "pylab.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is a good idea to clear the session (remove graphs etc from GPU/CPU) before defining a new model\n",
    "K.clear_session()\n",
    "\n",
    "# Init new feedforward network model from keras\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer connected a layer with 1 output nodes\n",
    "model.add(Dense(1, activation='linear', input_shape=(x_train.shape[1],)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=RMSprop(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = mean_squared_error(y_train, model.predict(x_train, verbose=0))\n",
    "test_error = mean_squared_error(y_test, model.predict(x_test, verbose=0))\n",
    "print('Train error=%f test error=%f' % (train_error, test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test, verbose=0)\n",
    "pylab.plot(y_test, y_test_pred, 'o')\n",
    "y_train_pred = model.predict(x_train, verbose=0)\n",
    "pylab.plot(y_train, y_train_pred, '.')\n",
    "pylab.plot([0,50],[0,50],'k-')\n",
    "pylab.xlabel('Ground truth')\n",
    "pylab.ylabel('Prediction')\n",
    "pylab.grid()\n",
    "pylab.legend(['Test', 'Train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.4 Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "\n",
    "# Choose AVG number of rooms as feature\n",
    "X = boston.data\n",
    "\n",
    "# Target / desired output\n",
    "y = boston.target\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It is a good idea to clear the session (remove graphs etc from GPU/CPU) before defining a new model\n",
    "K.clear_session()\n",
    "\n",
    "# Init new feedforward network model from keras\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer connected a hidden layer with 8 nodes\n",
    "model.add(Dense(2, activation='linear', input_shape=(x_train.shape[1],)))\n",
    "\n",
    "# You can add more layers like this:\n",
    "# model.add(Dense(8, activation='linear'))\n",
    "\n",
    "model.add(Dense(1, activation='linear', input_shape=(1,)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=RMSprop(lr=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_error = mean_squared_error(y_train, model.predict(x_train, verbose=0))\n",
    "test_error = mean_squared_error(y_test, model.predict(x_test, verbose=0))\n",
    "print('Train error=%f test error=%f' % (train_error, test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test, verbose=0)\n",
    "pylab.plot(y_test, y_test_pred, '.')\n",
    "pylab.plot([0,50],[0,50],'k-')\n",
    "pylab.xlabel('Ground truth')\n",
    "pylab.ylabel('Prediction')\n",
    "pylab.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = MinMaxScaler().fit(x_train)\n",
    "x_train = x_scaler.transform(x_train)\n",
    "x_test = x_scaler.transform(x_test)\n",
    "\n",
    "y_scaler = MinMaxScaler().fit(y_train.reshape(-1, 1))\n",
    "y_train = y_scaler.transform(y_train.reshape(-1, 1))\n",
    "y_test = y_scaler.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define (the same) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is a good idea to clear the session (remove graphs etc from GPU/CPU) before defining a new model\n",
    "K.clear_session()\n",
    "\n",
    "# Init new feedforward network model from keras\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer connected a layer with 2 nodes\n",
    "model.add(Dense(2, activation='linear', input_shape=(x_train.shape[1],)))\n",
    "\n",
    "model.add(Dense(1, activation='linear', input_shape=(1,)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=RMSprop(lr=.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=1000,\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = mean_squared_error(y_scaler.inverse_transform(y_train),\n",
    "                                 y_scaler.inverse_transform(model.predict(x_train, verbose=0)))\n",
    "test_error = mean_squared_error(y_scaler.inverse_transform(y_test),\n",
    "                                y_scaler.inverse_transform(model.predict(x_test, verbose=0)))\n",
    "print('Train error=%f test error=%f' % (train_error, test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test, verbose=0)\n",
    "pylab.plot(y_scaler.inverse_transform(y_test), y_scaler.inverse_transform(y_test_pred), '.')\n",
    "pylab.plot([0,50],[0,50],'k-')\n",
    "pylab.xlabel('Ground truth')\n",
    "pylab.ylabel('Prediction')\n",
    "pylab.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
