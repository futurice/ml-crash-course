{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digits recognition with Deep neural networks\n",
    "The goal of this exercise is get basic understanding in Deep Neural Networks (DNN)\n",
    "\n",
    "This example borrows bits and pieces from: https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py\n",
    "\n",
    "## Tasks:\n",
    "1. Load data\n",
    "2. Define the architecture of neural network\n",
    "3. Define loss function and optimizer to optimise it\n",
    "4. Compile and train the network\n",
    "5. Evaluate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import some important libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras is an easy to use Deep Learning library for Python\n",
    "import keras\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# Load MNIST dataset loading function\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Load Sequential model architecture\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Load Dense and Dropout layers ?\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Load RMSprop optimizer to minimize cost to train the network\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of classes\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert 28 x 28 images to 784 x 1 vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "### Normalize images from scale [0, 255] to [0, 1]\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert class vectors to binary class matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the architecture of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# It is a good idea to clear the session (remove graphs etc from GPU/CPU) before defining a new model\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define loss function and optimizer to optimise it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile and train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.2727 - acc: 0.9151 - val_loss: 0.1142 - val_acc: 0.9641\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0928 - acc: 0.9710 - val_loss: 0.1161 - val_acc: 0.9624\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0592 - acc: 0.9814 - val_loss: 0.0813 - val_acc: 0.9747\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0409 - acc: 0.9872 - val_loss: 0.0791 - val_acc: 0.9776\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0289 - acc: 0.9900 - val_loss: 0.0617 - val_acc: 0.9816\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0220 - acc: 0.9930 - val_loss: 0.0711 - val_acc: 0.9808\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0162 - acc: 0.9945 - val_loss: 0.0851 - val_acc: 0.9784\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0129 - acc: 0.9959 - val_loss: 0.0916 - val_acc: 0.9796\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.1037 - val_acc: 0.9771\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0101 - acc: 0.9966 - val_loss: 0.1023 - val_acc: 0.9782\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.10230890556128044\n",
      "Test accuracy: 0.9782\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise part-b: Convolutional neural network\n",
    "In convolutional neural network top Dense layers, which are extracting features from the images will be replaced with 2D Convolutional layers. \n",
    "\n",
    "## Convolutional layers\n",
    "\n",
    "In keras on input layer:\n",
    "```python\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "```\n",
    "And for all the other layers after the input layer:\n",
    "```python\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "```\n",
    "\n",
    "## Max Pooling layers\n",
    "\n",
    "It is also important to use Max Pooling layers to improve translation invariance and decrease the number of parameters. Typically, Max Pooling is added in the end of the each Convolution layer block. In Keras, one can add Max Pooling.\n",
    "\n",
    "```python\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "```\n",
    "\n",
    "\n",
    "## Typical design pattern for CNN network\n",
    "1. Convolutional layer\n",
    "2. Activation (typically ReLU)\n",
    "3. MaxPooling\n",
    "\n",
    "And then there are several of these blocks and then Dense classifier part in the end.\n",
    "\n",
    "1. Block 1:\n",
    "    1. Convolutional layer\n",
    "    2. Activation\n",
    "    3. MaxPooling\n",
    "2. Block 2:\n",
    "    1. Convolutional layer\n",
    "    2. Activation\n",
    "    3. MaxPooling\n",
    "3. Block 3:\n",
    "    1. Convolutional layer\n",
    "    2. Activation\n",
    "    3. MaxPooling\n",
    "4. Dense classification part\n",
    "    1. Flatten (to convert 2d matrices into a vert long vector)\n",
    "    2. Dense layer with quite large number of hidden units\n",
    "    3. Dense layer with `num_classes` hidden units\n",
    "    4. SoftMax activation to normalize outputs to [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define your network here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear previous models, it is important\n",
    "K.clear_session()\n",
    "\n",
    "# Init new model\n",
    "model = Sequential()\n",
    "\n",
    "# TODO: Add Convolutional layers here\n",
    "\n",
    "\n",
    "# DO NOT REMOVE THIS LINE. We need to flatten 2d matrices to vectors before MLP part of the network\n",
    "model.add(Flatten())\n",
    "\n",
    "# TODO: You can change the number hidden units (512) and activation fucntion if you want\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# DO NOT edit lines after this line (if you don't want to see how it breaks)\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
